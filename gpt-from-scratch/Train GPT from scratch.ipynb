{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d5976f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a3b952e",
   "metadata": {},
   "outputs": [],
   "source": [
    "text: str = Path(\"tiny-shakespeare.txt\").read_text()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90fa77d1",
   "metadata": {},
   "source": [
    "# Tokenizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f3750e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "50364b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "itos = dict(enumerate(chars))\n",
    "stoi = {v:k for k,v in itos.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "070555a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(s: str) -> list[int]:\n",
    "    return [stoi[c] for c in s]\n",
    "\n",
    "def decode(ints: list[int]) -> str:\n",
    "    return \"\".join(itos[i] for i in ints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bf724fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert \"yay\" == decode(encode(\"yay\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "85ae0726",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "data = torch.tensor(encode(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70f0faae-11c2-4857-badb-4c3c453e244e",
   "metadata": {},
   "source": [
    "# Test / Train Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "095059a9-53cd-4470-b3e9-091c3b1adfa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = int(0.9 * len(data))\n",
    "train_data = data[:n]\n",
    "test_data = data[n:]\n",
    "assert len(data) == len(train_data) + len(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7264228e-eb30-409f-a043-adf63845d1cd",
   "metadata": {},
   "source": [
    "# Inputs and Targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b310a40c-919e-4ce2-ab20-ab04f0e163c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "block_size = 8 # or context length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "71380b79-811e-414e-9b63-7502282cb172",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context=tensor([18]), target=47\n",
      "context=tensor([18, 47]), target=56\n",
      "context=tensor([18, 47, 56]), target=57\n",
      "context=tensor([18, 47, 56, 57]), target=58\n",
      "context=tensor([18, 47, 56, 57, 58]), target=1\n",
      "context=tensor([18, 47, 56, 57, 58,  1]), target=15\n",
      "context=tensor([18, 47, 56, 57, 58,  1, 15]), target=47\n",
      "context=tensor([18, 47, 56, 57, 58,  1, 15, 47]), target=58\n"
     ]
    }
   ],
   "source": [
    "x = train_data[:block_size]\n",
    "y = train_data[1:block_size+1]\n",
    "for t in range(block_size):\n",
    "    context = x[:t+1]\n",
    "    target = y[t]\n",
    "    print(f\"context={context}, target={target}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "164f93fd-eaeb-40f6-b6ff-f3a0899620f8",
   "metadata": {},
   "source": [
    "# Batching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e33a83fa-bf66-4bc8-a919-c6ae42bcb29b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[24, 43, 58,  5, 57,  1, 46, 43],\n",
       "         [44, 53, 56,  1, 58, 46, 39, 58],\n",
       "         [52, 58,  1, 58, 46, 39, 58,  1],\n",
       "         [25, 17, 27, 10,  0, 21,  1, 54]]),\n",
       " tensor([[43, 58,  5, 57,  1, 46, 43, 39],\n",
       "         [53, 56,  1, 58, 46, 39, 58,  1],\n",
       "         [58,  1, 58, 46, 39, 58,  1, 46],\n",
       "         [17, 27, 10,  0, 21,  1, 54, 39]]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(1337)\n",
    "batch_size = 4\n",
    "block_size = 8\n",
    "\n",
    "from torch import Tensor\n",
    "\n",
    "def get_batch(data: Tensor) -> Tensor:\n",
    "    start_ixs = torch.randint(len(data) - block_size, size=(batch_size,))\n",
    "    xs = torch.stack([data[i:i+block_size] for i in start_ixs])\n",
    "    ys = torch.stack([data[i+1:i+block_size+1] for i in start_ixs])\n",
    "    return xs, ys\n",
    "\n",
    "get_batch(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "15faa08e-a92a-44de-92eb-5be630275ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "torch.manual_seed(1337)\n",
    "\n",
    "class BGLM(nn.Module):\n",
    "    def __init__(self, vocab_size: int):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, vocab_size)\n",
    "\n",
    "    def forward(self, xs: Tensor, ys: Tensor = None):  # Both size (B,T)\n",
    "        logits = self.embedding(xs)  # size (B,T,C)\n",
    "        if ys is None:\n",
    "            loss = None\n",
    "            return logits, loss\n",
    "        \n",
    "        B, T, C = logits.shape\n",
    "        logits = logits.view(B*T, C)\n",
    "        ys = ys.view(B*T)\n",
    "        loss = F.cross_entropy(logits, ys)\n",
    "        return logits, loss\n",
    "\n",
    "    def generate(self, xs: Tensor, n: int) -> Tensor:\n",
    "        \"\"\"Expands each x in xs to have 'n' more tokens\"\"\"\n",
    "        for _ in range(n):\n",
    "            xs = self.generate1(xs)\n",
    "        return xs\n",
    "\n",
    "    def generate1(self, xs: Tensor) -> Tensor:\n",
    "        logits, _ = self(xs)\n",
    "        last_timestep = logits[:, -1, :]  # (B,C)\n",
    "        probs = F.softmax(last_timestep, dim=1)  # (B,C)\n",
    "        xs_next = torch.multinomial(probs, num_samples=1) # (B,1)\n",
    "        return torch.cat((xs, xs_next), dim=1) # (B,T+1)\n",
    "\n",
    "m = BGLM(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "df75ddad-ca0f-4d71-b100-1571ef3a9692",
   "metadata": {},
   "outputs": [],
   "source": [
    "xs_, ys_ = get_batch(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "00c949f2-0d6c-4d2b-a3ea-1775b8562aff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 6,  0, 21, 44,  1, 61, 43,  1],\n",
       "        [58, 52, 43, 57, 57,  2,  1, 57],\n",
       "        [ 1, 59, 52, 39, 41, 46, 47, 52],\n",
       "        [43, 42, 50, 39, 56,  6,  1, 50]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9545a3e3-6b25-4951-9860-13b60a25039b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 6,  0, 21, 44,  1, 61, 43,  1,  7],\n",
       "        [58, 52, 43, 57, 57,  2,  1, 57, 64],\n",
       "        [ 1, 59, 52, 39, 41, 46, 47, 52, 29],\n",
       "        [43, 42, 50, 39, 56,  6,  1, 50, 39]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits, loss = m(xs_, ys_)\n",
    "m.generate1(xs_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03ef6dbe-ed73-47fa-8b60-e7d8d92860ee",
   "metadata": {},
   "source": [
    "# Text Generation\n",
    "As we see below, the model is still random."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "28c1588b-08b2-4c7e-bbd1-9a951e2a2462",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\noRFJa!JKmRjtXzfN:CERiC-KuDHoiMIB!o3QHN\\n,SPyiFhRKuxZOMsB-ZJhsucL:wfzLSPyZalylgQUEU cLq,SqV&vW:hhir'q?\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initial_x = torch.tensor(stoi[\"\\n\"]).reshape((1,1))\n",
    "new_x = m.generate(initial_x, n=100)\n",
    "decode(new_x[0].tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "348349c7-7e12-42d0-9968-9c1c3187d6c2",
   "metadata": {},
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "28a5ed1e-d5fd-4118-81ce-eba1754241a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4290781021118164\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.AdamW(m.parameters(), lr=1e-3)\n",
    "\n",
    "batch_size = 32\n",
    "for _ in range(10000):\n",
    "    xs_, ys_ = get_batch(train_data)\n",
    "    logits, loss = m(xs_, ys_)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "afbb04d4-2ac8-4d47-8ea8-329bb93b3925",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ar bet!\n",
      "AMAs sod ke alved.\n",
      "Thup stheve de t\n",
      "I: ir w, l me sie hend lor ito'l an e\n",
      "\n",
      "I:\n",
      "Gochosen ea ar btamandd halind\n",
      "Aust, plt t wadzotl\n",
      "I bel qungnqthoth he m he de avellis k'l, tond sorangr?\n",
      "\n",
      "the tousButhe bott oze, t s d je hid t his Inces I my ig t\n",
      "Ril'swoll e pupat inouleacands-beriqu heamer te\n",
      "Wht s\n",
      "\n",
      "MI wect!-lltherotheve t fe;\n",
      "WAnd pporury t s ld tathat, ir V:\n",
      "A thesecin teot tit ado ilorer.\n",
      "Ply, d'stacoes, ld omat mealellly yererer EMEvesa! ie IZKI pave mautoofareanerllleyomerer but?\n",
      "The\n"
     ]
    }
   ],
   "source": [
    "new_x = m.generate(initial_x, n=500)\n",
    "print(decode(new_x[0].tolist()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
