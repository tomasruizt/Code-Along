{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72853041",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e38e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = torch.tensor([2.5, 2, 3])\n",
    "probs = torch.nn.functional.softmax(logits, dim=-1)\n",
    "print(probs)\n",
    "ax = sns.barplot(probs)\n",
    "ax.grid(axis=\"y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66048127",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = torch.multinomial(probs, num_samples=1000, replacement=True)\n",
    "print(torch.bincount(samples) / len(samples))\n",
    "ax = sns.histplot(samples, stat=\"probability\")\n",
    "ax.grid(axis=\"y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae65d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "spec_logits = torch.tensor([3.0, 2.0, 1.0])\n",
    "spec_probs = torch.nn.functional.softmax(spec_logits, dim=-1)\n",
    "spec_samples = torch.multinomial(spec_probs, num_samples=1000, replacement=True)\n",
    "print(spec_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c000c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.histplot(spec_samples, stat=\"probability\")\n",
    "ax.grid(axis=\"y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a1f79ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def rejection_sample(probs: torch.Tensor, spec_probs: torch.Tensor, idx: torch.Tensor):\n",
    "#     \"\"\"\n",
    "#     Target model distribution: q(x)\n",
    "#     Draft model distribution: p(x)\n",
    "#     \"\"\"\n",
    "#     q = probs[idx]\n",
    "#     p = spec_probs[idx]\n",
    "#     r = torch.rand(1)\n",
    "#     if r < torch.clamp(q / p, max=1.0):\n",
    "#         return idx\n",
    "#     new_p = torch.clamp(probs - spec_probs, min=0.0)\n",
    "#     return torch.multinomial(new_p, num_samples=1, replacement=True)[0]\n",
    "\n",
    "\n",
    "def rejection_sample(probs: torch.Tensor, spec_probs: torch.Tensor, idxs: torch.Tensor):\n",
    "    \"\"\"\n",
    "    Target model distribution: q(x)\n",
    "    Draft model distribution: p(x)\n",
    "    Vectorized implementation\n",
    "    \"\"\"\n",
    "    qs = probs[idxs]\n",
    "    ps = spec_probs[idxs]\n",
    "    rs = torch.rand(len(idxs))\n",
    "    keep_mask = rs < torch.clamp(qs / ps, max=1.0)\n",
    "    new_p = torch.clamp(probs - spec_probs, min=0.0)  # pseudo-probability\n",
    "    new_samples = torch.multinomial(new_p, num_samples=len(idxs), replacement=True)\n",
    "    return torch.where(keep_mask, idxs, new_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a0df706",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rej_samples = torch.tensor([rejection_sample(probs, spec_probs, x) for x in spec_samples])\n",
    "rej_samples = rejection_sample(probs, spec_probs, spec_samples)\n",
    "ax = sns.histplot(rej_samples, stat=\"probability\")\n",
    "ax.grid(axis=\"y\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7383e0a5",
   "metadata": {},
   "source": [
    "# Gumbel-Max Trick\n",
    "Sampling from the mulitnomial is equivalent to taking the argmax over logits plus standard Gumbel noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fab93e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gumbel_sample(logits: torch.Tensor, n: int):\n",
    "    gumbel_noise = - (- torch.rand((n, len(logits))).log()).log()\n",
    "    return torch.argmax(logits + gumbel_noise, dim=-1)\n",
    "\n",
    "gumbel_samples = gumbel_sample(logits, n=1000)\n",
    "ax = sns.histplot(gumbel_samples, stat=\"probability\")\n",
    "ax.grid(axis=\"y\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e79aa3b9",
   "metadata": {},
   "source": [
    "# Fused MM-Sample\n",
    "We now attempt to sample from the logits without materializing them.\n",
    "We compute the logits incrementally, and as we do, we keep track of the gumbel max index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9534dc0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 100\n",
    "hidden_size = 10\n",
    "weights = torch.rand((vocab_size, hidden_size))\n",
    "weights"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
