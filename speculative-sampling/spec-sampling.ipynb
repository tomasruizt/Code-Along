{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72853041",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "torch.set_default_device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e38e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = torch.tensor([2.5, 2, 3])\n",
    "probs = torch.nn.functional.softmax(logits, dim=-1)\n",
    "print(probs)\n",
    "ax = sns.barplot(probs.cpu())\n",
    "ax.grid(axis=\"y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66048127",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = torch.multinomial(probs, num_samples=1000, replacement=True)\n",
    "print(torch.bincount(samples) / len(samples))\n",
    "ax = sns.histplot(samples.cpu(), stat=\"probability\")\n",
    "ax.grid(axis=\"y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae65d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "spec_logits = torch.tensor([3.0, 2.0, 1.0])\n",
    "spec_probs = torch.nn.functional.softmax(spec_logits, dim=-1)\n",
    "spec_samples = torch.multinomial(spec_probs, num_samples=1000, replacement=True)\n",
    "print(spec_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c000c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.histplot(spec_samples.cpu(), stat=\"probability\")\n",
    "ax.grid(axis=\"y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a1f79ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def rejection_sample(probs: torch.Tensor, spec_probs: torch.Tensor, idx: torch.Tensor):\n",
    "#     \"\"\"\n",
    "#     Target model distribution: q(x)\n",
    "#     Draft model distribution: p(x)\n",
    "#     \"\"\"\n",
    "#     q = probs[idx]\n",
    "#     p = spec_probs[idx]\n",
    "#     r = torch.rand(1)\n",
    "#     if r < torch.clamp(q / p, max=1.0):\n",
    "#         return idx\n",
    "#     new_p = torch.clamp(probs - spec_probs, min=0.0)\n",
    "#     return torch.multinomial(new_p, num_samples=1, replacement=True)[0]\n",
    "\n",
    "\n",
    "def rejection_sample(probs: torch.Tensor, spec_probs: torch.Tensor, idxs: torch.Tensor):\n",
    "    \"\"\"\n",
    "    Target model distribution: q(x)\n",
    "    Draft model distribution: p(x)\n",
    "    Vectorized implementation\n",
    "    \"\"\"\n",
    "    qs = probs[idxs]\n",
    "    ps = spec_probs[idxs]\n",
    "    rs = torch.rand(len(idxs))\n",
    "    keep_mask = rs < torch.clamp(qs / ps, max=1.0)\n",
    "    new_p = torch.clamp(probs - spec_probs, min=0.0)  # pseudo-probability\n",
    "    new_samples = torch.multinomial(new_p, num_samples=len(idxs), replacement=True)\n",
    "    return torch.where(keep_mask, idxs, new_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a0df706",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rej_samples = torch.tensor([rejection_sample(probs, spec_probs, x) for x in spec_samples])\n",
    "rej_samples = rejection_sample(probs, spec_probs, spec_samples)\n",
    "ax = sns.histplot(rej_samples.cpu(), stat=\"probability\")\n",
    "ax.grid(axis=\"y\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7383e0a5",
   "metadata": {},
   "source": [
    "# Gumbel-Max Trick\n",
    "Sampling from the mulitnomial is equivalent to taking the argmax over logits plus standard Gumbel noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fab93e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gumbel_sample(logits: torch.Tensor, n: int):\n",
    "    gumbel_noise = -(-torch.rand((n, len(logits))).log()).log()\n",
    "    return torch.argmax(logits + gumbel_noise, dim=-1)\n",
    "\n",
    "\n",
    "gumbel_samples = gumbel_sample(logits, n=1000)\n",
    "ax = sns.histplot(gumbel_samples.cpu(), stat=\"probability\")\n",
    "ax.grid(axis=\"y\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e79aa3b9",
   "metadata": {},
   "source": [
    "# Fused MM-Sample\n",
    "We now attempt to sample from the logits without materializing them.\n",
    "We compute the logits incrementally, and as we do, we keep track of the gumbel max index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9534dc0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 100  # V\n",
    "hidden_size = 10  # D\n",
    "logits1 = torch.arange(-vocab_size / 2, vocab_size / 2)[None, :]  # [1, V]\n",
    "logits2 = torch.arange(vocab_size / 2, -vocab_size / 2, step=-1)[None, :]  # [1, V]\n",
    "logits = torch.cat([logits1, logits2], dim=0)  # [seq_len, V]\n",
    "seq_len = logits.shape[0]\n",
    "# use SVD to construct the hidden states that yield the logits\n",
    "# use pseudoinverse to construct the weights.\n",
    "# (there are many ways to do this, this is just one)\n",
    "# W @ H = L.T\n",
    "#  -> W = L.T @ H⁻¹\n",
    "U, S, Vt = torch.linalg.svd(logits, full_matrices=False)\n",
    "hidden_states = torch.cat(  # [D, seq_len]\n",
    "    [\n",
    "        U.T,\n",
    "        torch.rand((hidden_size - seq_len, seq_len)),  # padding\n",
    "    ],\n",
    ")\n",
    "weights = logits.T @ torch.linalg.pinv(hidden_states)  # [V, D]\n",
    "assert torch.allclose(weights @ hidden_states, logits.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68245803",
   "metadata": {},
   "source": [
    "## Baseline: PyTorch Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee03179a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(\n",
    "    weights: torch.Tensor,\n",
    "    hidden_states: torch.Tensor,\n",
    "    num_samples: int,\n",
    "    temperature: float,\n",
    "):\n",
    "    logits = weights @ hidden_states  # [seq_len, V]\n",
    "    logits -= torch.max(logits, dim=0, keepdim=True).values\n",
    "    probs = torch.nn.functional.softmax(logits / temperature, dim=0)  # [seq_len, V]\n",
    "    samples = torch.multinomial(probs.T, num_samples=num_samples, replacement=True)\n",
    "    return samples, probs\n",
    "\n",
    "\n",
    "def plot_samples(samples: torch.Tensor, seq_len: int, num_samples: int):\n",
    "    data = {\n",
    "        \"sample\": samples.flatten().cpu(),\n",
    "        \"seq\": [seq for seq in range(seq_len) for _ in range(num_samples)],\n",
    "    }\n",
    "    df = pd.DataFrame(data)\n",
    "    sns.histplot(df, x=\"sample\", hue=\"seq\", bins=100)\n",
    "\n",
    "\n",
    "num_samples = 1000\n",
    "samples, probs = sample(\n",
    "    weights, hidden_states, num_samples=num_samples, temperature=5\n",
    ")  # [seq_len, num_samples]\n",
    "plot_samples(samples, seq_len, num_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c477ef34",
   "metadata": {},
   "source": [
    "## Fused PyTorch Incremental Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e098bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def incremental_sample_pt(\n",
    "    weights: torch.Tensor,\n",
    "    hidden_states: torch.Tensor,\n",
    "    num_samples: int,\n",
    "    temperature: float,\n",
    "):\n",
    "    V, D = weights.shape\n",
    "    D, seq_len = hidden_states.shape\n",
    "    block_size = 8\n",
    "    # compute logits blocks\n",
    "    gumbel_max = float(\"-inf\") * torch.ones(size=(num_samples, seq_len))\n",
    "    gumbel_max_idx = torch.empty(size=(num_samples, seq_len), dtype=torch.long)\n",
    "    n_blocks = torch.ceil(torch.tensor(V) / block_size).int()\n",
    "    for blk_idx in range(n_blocks):\n",
    "        idx_from = blk_idx * block_size\n",
    "        idx_to = (blk_idx + 1) * block_size\n",
    "        w_blk = weights[idx_from:idx_to]  # [block_size, D]\n",
    "        logits_blk = w_blk @ hidden_states / temperature  # [seq_len, block_size]\n",
    "        unif_noise = torch.rand((num_samples, *logits_blk.shape))\n",
    "        gumbel_noise = -(-unif_noise.log()).log()\n",
    "        new_max, new_max_idx_local = torch.max(logits_blk + gumbel_noise, dim=1)\n",
    "        new_max_idx_global = idx_from + new_max_idx_local\n",
    "\n",
    "        replace_mask = new_max > gumbel_max\n",
    "        gumbel_max[replace_mask] = new_max[replace_mask]\n",
    "        gumbel_max_idx[replace_mask] = new_max_idx_global[replace_mask]\n",
    "    return gumbel_max_idx.T\n",
    "\n",
    "\n",
    "samples2 = incremental_sample_pt(weights, hidden_states, num_samples, temperature=5)\n",
    "plot_samples(samples2, seq_len, num_samples)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
