# Softmax and Sigmoid
The definition of the sigmoid is: 
$$ \text{sigmoid}(x) = \frac{1}{1+e^{-x}} $$

The relations between the sigmoid and the softmax are:
$$
\begin{align*}
\text{softmax}(x_i) 
&= \frac{e^{x_i}}{\sum_{j=1}^{n} e^{x_j}} \\
&= \frac{1}{\sum_{j=1}^{n} e^{x_j} / e^{x_i}} \\
&= \frac{1}{ 1+ \sum_{j=1, j\neq i}^{n} e^{x_j - x_i}} \\
\end{align*}
$$

For the binary case $n=2$, we have
$$
\begin{align*}
\text{softmax}(x_1)
&= \frac{1}{1+e^{x_2 - x_1}} \\
&= \frac{1}{1+e^{-(x_1 - x_2)}} \\
&= \text{sigmoid}(x_1 - x_2)
\end{align*}
$$

# Bernoulli Distribution
$$ B(x; p) = p^x (1-p)^{1-x} $$
where $x \in \{0, 1\}$.
$$ B(x=0; p) = 1-p $$
$$ B(x=1; p) = p $$