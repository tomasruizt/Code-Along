{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c93fdb9-bca1-4729-b883-842b0bd1f647",
   "metadata": {},
   "source": [
    "# 8.3 Reverse-Mode \"Adjoint\" Differentiation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "189d0f2a-acda-4409-b491-b3a5c164ca02",
   "metadata": {},
   "source": [
    "Assume that we have a matrix $A(p) \\in \\mathcal{R}^{n \\times n}$ that depends on some parameters $p \\in \\mathcal{R}^{m}$. Assume furthermore, that we form a linear system with $A(p)$, and a given a fixed $b \\in \\mathcal{R}^n$.\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "A(p) x = b \\\\\n",
    "\\implies x = A(p)^{-1} b\n",
    "\\end{align*}\n",
    "$$\n",
    "Where $x \\in \\mathcal{R}^n$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e75c26e9-3ba1-4ab7-900f-5278c0317211",
   "metadata": {},
   "source": [
    "Assume then, that we use $x$ within some operation $f(x)$. For example:\n",
    "$$ f(x) = || x ||_2 = \\langle x, x \\rangle^{0.5}$$\n",
    "\n",
    "Next, we want minimize $f(x)$ and are therfore interested in the differential $df$, and the gradient $\\nabla f$.\n",
    "$$\n",
    "\\frac{df}{dp} = \\frac{df}{dx} \\frac{dx}{dp}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1fce3df-c773-460b-a661-9b301e3a3b43",
   "metadata": {},
   "source": [
    "We know that:\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\frac{df}{dx} \n",
    "&= f'(x) \\\\\n",
    "&= 0.5 \\langle x,x \\rangle ^{-0.5} \\cdot 2 x \\\\\n",
    "&= \\frac{x}{f(x)}\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a885ec4-cd5b-4149-b728-1e6cdece09fc",
   "metadata": {},
   "source": [
    "Another way of putting this is $f(x) = g(h(x))$ where $h(x) = \\langle x, x \\rangle$, and $g(u) = u^{0.5}$. \n",
    "\n",
    "It follows that $g'(u) = 0.5 u^{-0.5}$, and $h'(x) = 2x $.\n",
    "\n",
    "Then:\n",
    "\n",
    "$$ \n",
    "\\begin{align*}\n",
    "f'(x) \n",
    "&= g'(h(x)) \\cdot h'(x) \\\\\n",
    "&= 0.5 {\\langle x, x \\rangle}^{-0.5} \\cdot 2x\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f63409a8-03ee-42c3-9d24-655b68479891",
   "metadata": {},
   "source": [
    "Now, back to $\\frac{dx}{dp}$. Since $x = A(p)^{-1} b$:\n",
    "$$\n",
    "\\begin{align*}\n",
    "dx\n",
    "&= dA(p)^{-1} b + A(p)^{-1} \\underbrace{db}_0 \\\\\n",
    "&= \\underbrace{dA(p)^{-1}}_{d(A^{-1}) = - A^{-1} dA A^{-1}} b \\\\\n",
    "&= - A^{-1} dA \\ \\underbrace{A^{-1} b}_x & \\text{assume } A := A(p) \\\\\n",
    "&= - A^{-1} dA \\ x\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d787cb10-3d8d-4725-a8a0-ceac92e3e540",
   "metadata": {},
   "source": [
    "And since $df = f'(x) dx$, we can substitute $f'(x)$, and $dx$ to find the differential $df$\n",
    "$$\n",
    "\\begin{align*}\n",
    "df \n",
    "&= \\underbrace{\\frac{x^T}{f(x)} \\cdot (-A^{-1}}_{v^T} dA \\ x) \\\\\n",
    "&= v^T dA \\ x\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65f24a75-448e-4b2b-9fef-3d0529936a6b",
   "metadata": {},
   "source": [
    "The vector $v$ can be found like this:\n",
    "$$\n",
    "\\begin{align*}\n",
    "v^T\n",
    "&= - \\frac{x^T}{f(x)} A^{-1} \\\\\n",
    "\\implies v^T A &= - \\frac{x^T}{f(x)} \\\\\n",
    "\\implies A^T v &= - \\frac{x}{f(x)} \\\\\n",
    "\\implies v &= - (A^T)^{-1} \\frac{x}{f(x)}\n",
    "\\end{align*}\n",
    "$$\n",
    "This means that $v$ is the result of solving the linear sytem with matrix $A^T$ and vector $-f'(x)$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26fb4682-c3d0-44db-979c-45f5d4bcea76",
   "metadata": {},
   "source": [
    "Finally, we are interested in $\\frac{df}{dp}$:\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\frac{df}{dp}\n",
    "&= v^T \\frac{dA}{dp} x \\\\\n",
    "&= v^T \\underbrace{A'(p)}_{(n \\times n \\times m) \\text{ tensor}} x\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b6753a55-274c-453c-b22d-a3665c5d76c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([16.,  4., 20.,  4.])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "p = torch.tensor([1.0, 2, 3, 4], requires_grad=True)\n",
    "m = 4\n",
    "assert p.size(0) == m\n",
    "\n",
    "b = torch.tensor([4.0, 3, 2, 1])\n",
    "n = 4\n",
    "assert b.size(0) == n\n",
    "\n",
    "def A(p):\n",
    "    row1 = torch.stack([p[0] + p[1], p[2]**2])\n",
    "    row2 = torch.stack([p[3] - p[2], p[0]**3])\n",
    "    quarter = torch.stack([row1, row2])\n",
    "    half = torch.cat([quarter, quarter])\n",
    "    full = torch.cat([half, half], 1)\n",
    "    return full + torch.eye(4)\n",
    "\n",
    "loss = A(p)\n",
    "loss.backward(gradient=torch.ones_like(loss))\n",
    "\n",
    "p.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a9b52156-0997-45ed-9cce-53f49f6eb6b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 2.8000,  0.4667,  0.8000, -1.5333], grad_fn=<LinalgSolveExBackward0>)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.linalg import solve\n",
    "\n",
    "def x(A):\n",
    "    return solve(A, b)\n",
    "\n",
    "x(A(p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a749573-30e6-4e3b-a19b-578e6b3206f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    return torch.norm(x)\n",
    "\n",
    "def fprime(x):\n",
    "    return x / f(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "827c6f3d-340f-47bf-b328-6c081f960532",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.1711, -1.0255,  0.4305, -0.4239], grad_fn=<NegBackward0>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def v(p):\n",
    "    return -solve(A(p).T, fprime(x(A(p))))\n",
    "\n",
    "v(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2fd0c27-03d0-402f-a5a1-001cbbe99831",
   "metadata": {},
   "source": [
    "# Numerical Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3e5f0309-4df0-4dd5-9bce-1973007bd671",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dA():\n",
    "    torch.manual_seed(0)\n",
    "    return torch.randn(m, m) * 1e-5\n",
    "\n",
    "def finite_difference(p):\n",
    "    A_ = A(p)\n",
    "    return f(x(A_ + dA())) - f(x(A_))\n",
    "\n",
    "def df(p):\n",
    "    return v(p) @ dA() @ x(A(p))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d7887ce-3d7c-46ac-9052-06e62d053fad",
   "metadata": {},
   "source": [
    "The analytical implementation agrees with the finite difference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "306f40cf-a26d-41cd-82f4-47b038f0cc63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(-6.1512e-05, grad_fn=<SubBackward0>),\n",
       " tensor(-6.1578e-05, grad_fn=<DotBackward0>))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finite_difference(p), df(p)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
