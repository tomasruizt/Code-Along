{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ea055aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "using Symbolics\n",
    "using LinearAlgebra\n",
    "using ForwardDiff"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c5abdb7",
   "metadata": {},
   "source": [
    "# Matrix Gradients\n",
    "\n",
    "The goal of this notebook is to investigate what precisely a _matrix gradient_ is, because it is different from the concept of the _gradient with respect to a matrix_. To be precise, I will investigate the derivate of a matrix function with respect to a matrix input.\n",
    "\n",
    "For our examples, I will use a 2x2 matrix:\n",
    "$$ A = \\begin{bmatrix} a_{11} & a_{12} \\\\ a_{21} & a_{22} \\end{bmatrix}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "034747de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$$ \\begin{equation}\n",
       "\\left[\n",
       "\\begin{array}{cc}\n",
       "a_{11} & a_{12} \\\\\n",
       "a_{21} & a_{22} \\\\\n",
       "\\end{array}\n",
       "\\right]\n",
       "\\end{equation}\n",
       " $$"
      ],
      "text/plain": [
       "2×2 Matrix{Num}:\n",
       " a_11  a_12\n",
       " a_21  a_22"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@variables a_11 a_12 a_21 a_22;\n",
    "A = [a_11 a_12; a_21 a_22]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50780c5a",
   "metadata": {},
   "source": [
    "Lets begin with the gradient of a scalar function of $A$ with respect to $A$. Then I will continue with the gradient of a matrix function of $A$ with respect to $A$.\n",
    "\n",
    "## 1. Scalar Function\n",
    "As an exmpale for a scalar function $f_s(A)$, I use the [Frobenium norm](https://mathworld.wolfram.com/FrobeniusNorm.html), which maps a matrix $A$ to a scalar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "722f5fdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$$ \\begin{equation}\n",
       "\\sqrt{a_{11}^{2} + a_{12}^{2} + a_{21}^{2} + a_{22}^{2}}\n",
       "\\end{equation}\n",
       " $$"
      ],
      "text/plain": [
       "sqrt(a_11^2 + a_12^2 + a_21^2 + a_22^2)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_s(X) = sqrt(sum(x^2 for x in X));  # Frobenius norm\n",
    "f_s(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e2ce2ed",
   "metadata": {},
   "source": [
    "Then gradient of $f_s(A)$ with respect to $A$ is $\\nabla_A f_s (A)$ is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c5b755d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$$ \\begin{equation}\n",
       "\\left[\n",
       "\\begin{array}{cc}\n",
       "\\frac{a_{11}}{\\sqrt{a_{11}^{2} + a_{12}^{2} + a_{21}^{2} + a_{22}^{2}}} & \\frac{a_{12}}{\\sqrt{a_{11}^{2} + a_{12}^{2} + a_{21}^{2} + a_{22}^{2}}} \\\\\n",
       "\\frac{a_{21}}{\\sqrt{a_{11}^{2} + a_{12}^{2} + a_{21}^{2} + a_{22}^{2}}} & \\frac{a_{22}}{\\sqrt{a_{11}^{2} + a_{12}^{2} + a_{21}^{2} + a_{22}^{2}}} \\\\\n",
       "\\end{array}\n",
       "\\right]\n",
       "\\end{equation}\n",
       " $$"
      ],
      "text/plain": [
       "2×2 Matrix{Num}:\n",
       " a_11 / sqrt(a_11^2 + a_12^2 + a_21^2 + a_22^2)  …  a_12 / sqrt(a_11^2 + a_12^2 + a_21^2 + a_22^2)\n",
       " a_21 / sqrt(a_11^2 + a_12^2 + a_21^2 + a_22^2)     a_22 / sqrt(a_11^2 + a_12^2 + a_21^2 + a_22^2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ForwardDiff.gradient(f_s, A)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a117e67",
   "metadata": {},
   "source": [
    "## 2. Matrix Function\n",
    "Let's use matrix exponentiation $A^3 = A * A * A$, as an example of a matrix function $f_m(A)$, which maps a 2x2 matrix into another 2x2 matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e35b5c4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$$ \\begin{equation}\n",
       "\\left[\n",
       "\\begin{array}{cc}\n",
       "a_{11} \\left( a_{11}^{2} + a_{12} a_{21} \\right) + \\left( a_{11} a_{12} + a_{12} a_{22} \\right) a_{21} & \\left( a_{11}^{2} + a_{12} a_{21} \\right) a_{12} + \\left( a_{11} a_{12} + a_{12} a_{22} \\right) a_{22} \\\\\n",
       "a_{11} \\left( a_{11} a_{21} + a_{21} a_{22} \\right) + \\left( a_{12} a_{21} + a_{22}^{2} \\right) a_{21} & \\left( a_{11} a_{21} + a_{21} a_{22} \\right) a_{12} + \\left( a_{12} a_{21} + a_{22}^{2} \\right) a_{22} \\\\\n",
       "\\end{array}\n",
       "\\right]\n",
       "\\end{equation}\n",
       " $$"
      ],
      "text/plain": [
       "2×2 Matrix{Num}:\n",
       " a_11*(a_11^2 + a_12*a_21) + (a_11*a_12 + a_12*a_22)*a_21  …  (a_11^2 + a_12*a_21)*a_12 + (a_11*a_12 + a_12*a_22)*a_22\n",
       " a_11*(a_11*a_21 + a_21*a_22) + (a_12*a_21 + a_22^2)*a_21     (a_11*a_21 + a_21*a_22)*a_12 + (a_12*a_21 + a_22^2)*a_22"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_m(X) = X * X * X\n",
    "f_m(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18633776",
   "metadata": {},
   "source": [
    "Let's ask again what the gradient of the matrix function $f_m(A)$ with respect to its input matrix $A$ is, so $\\nabla_A f_m(A)$.\n",
    "$$ \n",
    "f_m(A) = A * A * A\n",
    "$$\n",
    "\n",
    "and the differential is\n",
    "$$\n",
    "\\begin{align}\n",
    "df_m &=  dA A^2 + A dA A + A^2 dA\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fecf2f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_m(x, dx) = dx*x^2 + x*dx*x + x^2*dx;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61299f15",
   "metadata": {},
   "source": [
    "The solution below does not access to $dx$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b2bf5a4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "grad_A (generic function with 1 method)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grad_A(dA) = ForwardDiff.jacobian(f_m, A) * vec(dA) # <- ForwardDiff.gradient(f_m, A) throws an exception!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a69d3ee",
   "metadata": {},
   "source": [
    "### Checking with finite differences\n",
    "The finite difference gives a ground truth approximation to verify that the gradient implementation is correct.\n",
    "    $$ df = (f(X + \\delta X) - f(X)) \\cdot dX $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "99de8315",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2×2 Matrix{Float64}:\n",
       " 0.173128  -0.383209\n",
       " 0.296065  -0.0614478"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = randn(2, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "de3528f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2×2 Matrix{Float64}:\n",
       " -6.54275e-9  -1.58793e-8\n",
       " -1.31257e-9   7.22189e-9"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "δY = randn(2, 2) * 1e-8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f31eea4",
   "metadata": {},
   "source": [
    "Gradient with finite difference:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4aa971d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2×2 Matrix{Float64}:\n",
       " -1.11879e-9   3.6185e-9\n",
       " -1.56869e-9  -1.0255e-9"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finite_difference = f_m(Y + δY) - f_m(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83912ce3",
   "metadata": {},
   "source": [
    "Gradient with linear function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fa85e945",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2×2 Matrix{Float64}:\n",
       " -1.11879e-9   3.6185e-9\n",
       " -1.56869e-9  -1.0255e-9"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_m(Y, δY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6226f31",
   "metadata": {},
   "source": [
    "Gradient with symbolic Jacobian:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4f20cb42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$$ \\begin{equation}\n",
       "\\left[\n",
       "\\begin{array}{c}\n",
       "-1.1188 \\cdot 10^{-9} \\\\\n",
       "-1.5687 \\cdot 10^{-9} \\\\\n",
       "3.6185 \\cdot 10^{-9} \\\\\n",
       "-1.0255 \\cdot 10^{-9} \\\\\n",
       "\\end{array}\n",
       "\\right]\n",
       "\\end{equation}\n",
       " $$"
      ],
      "text/plain": [
       "4-element Vector{Num}:\n",
       " -1.1187921176613405e-9\n",
       " -1.5686865959619862e-9\n",
       "  3.6184972720749093e-9\n",
       " -1.0254980938277533e-9"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "substitute(grad_A(δY), Dict(a_11 => Y[1, 1], a_12 => Y[1, 2], a_21 => Y[2, 1], a_22 => Y[2, 2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c84bf1c4",
   "metadata": {},
   "source": [
    "All solutions above are equal."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01c3e457",
   "metadata": {},
   "source": [
    "### Question\n",
    "Are the gradients dependent on concrete $\\delta Y$ that we pass?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a6513245",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "δ (generic function with 1 method)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "δ(X) = randn(size(X)) * 1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3c8ab754",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2×2 Matrix{Int64}:\n",
       " 1  2\n",
       " 3  4"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = [1 2; 3 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a0d20621",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2×2 Matrix{Float64}:\n",
       " -0.00129718  -0.000196377\n",
       " -0.00326642  -0.000935364"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_m(Y, δ(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c4d43986",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2×2 Matrix{Float64}:\n",
       " -0.000551738   4.94507e-5\n",
       " -0.0031414    -0.0027555"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_m(Y, δ(Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ace58c1",
   "metadata": {},
   "source": [
    "Yes, $df$ changes dependening on $\\delta Y$. But perhaps, if we divide back element-wise by $\\delta Y$, we could the same gradient for any $\\delta Y$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bbcfe5e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2×2 Matrix{Float64}:\n",
       " -68.4698   24.2113\n",
       "  24.2964  -32.4979"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = δ(Y)\n",
    "df_m(Y, d) ./ d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bb51144b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2×2 Matrix{Float64}:\n",
       " 0.759711   -4.34671\n",
       " 9.03675   -54.1683"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = δ(Y)\n",
    "df_m(Y, d) ./ d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5391c9c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2×2 Matrix{Float64}:\n",
       " 16.9079  -112.07\n",
       " 47.0862    30.1931"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = δ(Y)\n",
    "df_m(Y, d) ./ d"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.10.0",
   "language": "julia",
   "name": "julia-1.10"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
